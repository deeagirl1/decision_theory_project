{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dots & Boxes - Decision Theory Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this project, we are going to implement the dots & boxes game by using different techniques learned during this course. The idea is to create the dots & boxes environment and play with a smart agent and a random agent. The agents will simulate the game. Our goal is to make the smart agent more efficient than the smart agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition of game\n",
    "Dots and boxes is a game originally played with pen and paper. The aim of the game is to get more boxes in your possession then your opponent. You start the game with an empty grid. This grid consists of a square (x,y where x and y have the same length) with horizontal dots evenly divided and vertical dots beneath those horizontal dots. So, each dot it in a right angle with every other dot. When You connect four dots you can form a square or in this game called a block. You and your opponent take turns to join up two adjacent dots with a line. If any player forms a box they get a point and they also get to make another move. The player with the most boxes will win. This is not a game of chance; strategies can help a player to win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definition of the environment\n",
    "### 2.1. States\n",
    "This game consists of a state space with a grid of 3 by 3. The environment can be in one of these states $S = (S_0, S_1, ..., S_n)$, where n has a a value of 13, which is the end state, because you can maximum only set 2*6 lines in-between dots this is not including the beginning state without any lines. After every turn the program will notify what the current state is and who plays next. This environment consists of:\n",
    "- The initialisation with:\n",
    "    - n as the size of the grid\n",
    "    - hor_links as defining the horizontal dot connections (default with all false)\n",
    "    - ver_links as defining the vertical dot connections (default all false)\n",
    "    - owners to define the owners of the boxes (default all empty)\n",
    "    - alphabets to create the x-labels on the grid\n",
    "    - numbers to create the y-labels on the grid\n",
    "    - dots consists of every possible dot coordinate on the grid\n",
    "    - __state as all the possible connection coordinates\n",
    "    - player1 as name for player 1 (default is A)\n",
    "    - player2 as name for player 2 (default is B)\n",
    "    - player as the player of the current turn (default is player1)\n",
    "    - gameOver to indicate if the game has finished\n",
    "    - rewardsPlayer1 is a list of rewards for player one\n",
    "    - rewardsPlayer2 is a list of rewards for player two\n",
    "    - actions consists of all the possible actions in one game (an action will be removed when played)\n",
    "- The initialisation which starts up a new game \n",
    "- The printer which prints the current state space (with part_print as helper)\n",
    "- show_game which shows the current state of the game\n",
    "- play_game which does the next action (it can be decided if you want printed output or not.)\n",
    "- is_game_over which checks if the game is done\n",
    "- total_rewardsPlayer1_calculator which calculates all the reward together from player 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Reward:\n",
    "    def __init__(self, name, val):\n",
    "        self.name = name\n",
    "        self.val = val\n",
    "    \n",
    "    def toString(self):\n",
    "        return self.name+\"|\"+str(self.val)\n",
    "\n",
    "class TransitionProb:\n",
    "    def __init__(self, Possible_actions):\n",
    "        self.Possible_actions = Possible_actions\n",
    "    \n",
    "    def get_transitionProb(self):\n",
    "        if len(self.Possible_actions) > 0:\n",
    "            return 1 / len(self.Possible_actions)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"the possible actions are {self.Possible_actions} and the transition probability is {self.get_transitionProb()} \"\n",
    "\n",
    "class DotsAndBoxes:\n",
    "    def __init__(self, n, player1='A', player2='B', randomPlay=False, printResult=True):\n",
    "        self.n = n\n",
    "        self.hor_links = [False] * (n * (n + 1))  # Defining horizontal link connections(now all False)\n",
    "        self.ver_links = [False] * (n * (n + 1))  # Defining vertical link connections(now all False)\n",
    "        self.owners = [' '] * (n ** 2)  # defining the owners of created boxes(now blank)\n",
    "        self.alphabets = list('abcdefghijklmnopqrstuvwxyz')[0:(n + 1)]\n",
    "        self.numbers = list('0123456789')[0:(n + 1)]\n",
    "        self.dots = []  # List for points ID\n",
    "        for num in self.numbers:\n",
    "            for i in self.alphabets:\n",
    "                self.dots.append(i + num)\n",
    "        if randomPlay:\n",
    "            self.player1 = \"random_player\"\n",
    "        else:\n",
    "            self.player1=player1\n",
    "        self.player2 = player2\n",
    "        self.prev_text = \"\"\n",
    "        self.player= self.player1\n",
    "        self.gameOver = False\n",
    "        self.rewardsPlayer1= []\n",
    "        self.rewardsPlayer2= []\n",
    "        self.actions= [[\"a0\",\"a1\"],[\"a1\",\"a2\"],[\"b0\",\"b1\"],[\"b1\",\"b2\"],[\"c0\",\"c1\"],[\"c1\",\"c2\"],[\"a0\",\"b0\"],[\"b0\",\"c0\"],[\"a1\",\"b1\"],[\"b1\",\"c1\"],[\"a2\",\"b2\"],[\"b2\",\"c2\"]]\n",
    "        self.state=[] #init\n",
    "        self.states= self.get_states_from_transitions(self.T(self.state))\n",
    "        if randomPlay:\n",
    "            randomVar= random.choice(self.actions.copy())\n",
    "            self.play_game(randomVar[0],randomVar[1], printResult)\n",
    "            \n",
    "\n",
    "    # part of the following printer function : Helps in same line printing\n",
    "    def part_print(self, new_text, end=\"\"):\n",
    "        self.prev_text = self.prev_text + new_text\n",
    "        if end == \"\\n\":\n",
    "            print(self.prev_text)\n",
    "            self.prev_text = \"\"\n",
    "        else:\n",
    "            self.prev_text = self.prev_text + end\n",
    "        \n",
    "    # Prints the dots and links and scores in a user friendly manner\n",
    "    def printer(self, hor_links, ver_links, owners):\n",
    "        new_hor_links = []\n",
    "        for i in hor_links:\n",
    "            if i:\n",
    "                new_hor_links.append('-------')\n",
    "            else:\n",
    "                new_hor_links.append('       ')\n",
    "        new_ver_links = []\n",
    "        for i in ver_links:\n",
    "            if i:\n",
    "                new_ver_links.append('|       ')\n",
    "            else:\n",
    "                new_ver_links.append('        ')\n",
    "        char = '+'\n",
    "        hor_index = 0\n",
    "        ver_index = 0\n",
    "        owner_index = 0\n",
    "        row_index = 0\n",
    "        print('-' * (((self.n + 1) *5) + 8) + '\\n')\n",
    "        print(\"    a       b       c       d       e       f       g       h       i       j      \"[0:((self.n + 1) * 7) + 1] + '\\n')\n",
    "        while True:\n",
    "            print(\" \" + str(row_index) + ' ', end=' ')\n",
    "            for i in range(self.n):\n",
    "                self.part_print(char, \"\")\n",
    "                self.part_print(new_hor_links[hor_index], \"\")\n",
    "                hor_index += 1\n",
    "            self.part_print(char, \"\\n\")\n",
    "            row_index += 1\n",
    "            if (hor_index) == len(new_hor_links):\n",
    "                break\n",
    "            print(\"   \", end=' ')\n",
    "            for i in range(self.n + 1):\n",
    "                self.part_print(new_ver_links[ver_index], \"\")\n",
    "                ver_index += 1\n",
    "            self.part_print(\"\", \"\\n\")\n",
    "            ver_index -= (self.n + 1)\n",
    "            print(\"   \", end=' ')\n",
    "            for i in range(self.n):\n",
    "                if ver_links[ver_index]:\n",
    "                    self.part_print(\"|   \" + owners[owner_index] + \"   \", \"\")\n",
    "                else:\n",
    "                    self.part_print(\"    \" + owners[owner_index] + \"   \", \"\")\n",
    "                owner_index += 1\n",
    "                ver_index += 1\n",
    "            if ver_links[ver_index]:\n",
    "                self.part_print(\"|      \", \"\\n\")\n",
    "            else:\n",
    "                self.part_print(\"       \", \"\\n\")\n",
    "            ver_index += 1\n",
    "            \n",
    "        print('\\n\\n' + '-' * (((self.n + 1) * 5) + 8))\n",
    "        print(\"\\nscore of player \"+ self.player1+\" : \" + str(self.total_rewardsPlayer1_calculator()))\n",
    "        print(\"score of player \"+ self.player2+ \" : \" + str(self.total_rewardsPlayer2_calculator()))\n",
    "    \n",
    "    def show_game(self):\n",
    "        self.printer(self.hor_links, self.ver_links, self.owners)  # prints the boxes\n",
    "        print(f\"it is now the turn of player {self.player}\")\n",
    "\n",
    "    def play_game(self, point1, point2, printResult=True): #play game instead of start\n",
    "        if point1 != \"\" and point2 != \"\":\n",
    "            pos1 = self.dots.index(point1)\n",
    "            pos2 = self.dots.index(point2)    \n",
    "            if self.actions.__contains__([point1, point2]):\n",
    "                self.state.append([point1,point2])\n",
    "                box_id = self.create_link(pos1, pos2, self.hor_links, self.ver_links)\n",
    "                amount_change=0 #amount of boxes that changed owner\n",
    "                for corner in box_id:\n",
    "                    if self.change_owner(corner, self.owners, self.player):\n",
    "                        amount_change+=1\n",
    "                    \n",
    "                self.actions.remove([point1,point2])\n",
    "                if amount_change>0:  # if true the current player will continue the game\n",
    "                    if self.player == self.player1:\n",
    "                        reward = Reward(self.player1+ \"made a square\", amount_change)\n",
    "                        self.rewardsPlayer1.append(reward)\n",
    "                        reward = Reward(self.player1+ \"made a square\", -amount_change)\n",
    "                        self.rewardsPlayer2.append(reward)\n",
    "                        if printResult:\n",
    "                            print(f\"{self.player1} got 1 reward\")\n",
    "                    else:\n",
    "                        reward = Reward(self.player2+\" made a square\", -amount_change)\n",
    "                        self.rewardsPlayer1.append(reward)\n",
    "                        reward = Reward(self.player2+\" made a square\", amount_change)\n",
    "                        self.rewardsPlayer2.append(reward)\n",
    "                        if printResult:\n",
    "                            print(f\"{self.player2} got 1 reward\")\n",
    "                else:\n",
    "                    self.change_player()\n",
    "            elif printResult:\n",
    "                print(f\"The points exists already: { self.actions.__contains__([point1, point2])}\")\n",
    "            if printResult:\n",
    "                self.printer(self.hor_links, self.ver_links, self.owners)  # prints the boxes\n",
    "                print(f\"it is now the turn of player {self.player}\")\n",
    "        \n",
    "        if self.is_game_over() & printResult:\n",
    "            scorep1=self.total_rewardsPlayer1_calculator()\n",
    "            scorep2= self.total_rewardsPlayer2_calculator()\n",
    "            print(\"\\nGame over!!\")\n",
    "            if scorep1 < scorep2:\n",
    "                print(\"\\nplayer \"+ self.player2 + \" has won the match with \" + str(scorep2) + \" points\")\n",
    "            elif scorep1 > scorep2:\n",
    "                print(\"\\nplayer \"+ self.player1 + \" has won the match with \" + str(scorep1) + \" points\")\n",
    "            else:\n",
    "                print(\"\\nthe game is draw!\")\n",
    "    \n",
    "    def is_game_over(self):\n",
    "        if ' ' not in self.owners:\n",
    "            self.gameOver = True\n",
    "        return self.gameOver\n",
    "        \n",
    "    def is_linked(self, pos1, pos2, hor_links, ver_links):\n",
    "        if pos1 > pos2:\n",
    "            pos1, pos2 = pos2, pos1\n",
    "        if (pos1 + 1) % (self.n + 1) == 0 and pos2 % (self.n + 1) == 0:\n",
    "            return False\n",
    "        if pos2 - pos1 == self.n + 1:\n",
    "            return ver_links[pos1]\n",
    "        elif pos2 - pos1 == 1:\n",
    "            return hor_links[pos1 - ((pos1 + 1) // (self.n + 1))]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Checks if the given four points are joined correctly so that a box is formed\n",
    "    def is_box_completed(self, pos1, pos2, pos3, pos4, hor_links, ver_links):\n",
    "        all = [pos1, pos2, pos3, pos4]\n",
    "        all.sort()\n",
    "        for i in all:\n",
    "            if i < 0 or i > (((self.n + 1) ** 2) - 1):\n",
    "                return False\n",
    "        if (self.is_linked(all[0], all[1], hor_links, ver_links) and self.is_linked(all[2], all[3], hor_links,\n",
    "                                                                                    ver_links)) and (\n",
    "                self.is_linked(all[0], all[2], hor_links, ver_links) and self.is_linked(all[1], all[3], hor_links,\n",
    "                                                                                        ver_links)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # checks if the given points are joined and returns a list of topmost left points of the box created .\n",
    "    # if no box is formed, returns [].\n",
    "    # raises error if the points cannot be joined !\n",
    "    def create_link(self, pos1, pos2, hor_links, ver_links):\n",
    "        e = Exception(\"Error\")\n",
    "        if self.is_linked(pos1, pos2, hor_links, ver_links):\n",
    "            raise RuntimeError(\"already present\")\n",
    "        if pos1 > pos2:\n",
    "            pos1, pos2 = pos2, pos1\n",
    "        if (pos1 + 1) % (self.n + 1) == 0 and pos2 % (self.n + 1) == 0:\n",
    "            raise e\n",
    "        if pos2 - pos1 == self.n + 1:\n",
    "            ver_links[pos1] = True\n",
    "            box_id = []\n",
    "            check = self.is_box_completed(pos1, pos2, pos1 - 1, pos2 - 1, hor_links, ver_links)\n",
    "            if check:\n",
    "                box_id.append(pos1 - 1)\n",
    "            check = self.is_box_completed(pos1, pos2, pos1 + 1, pos2 + 1, hor_links, ver_links)\n",
    "            if check:\n",
    "                box_id.append(pos1)\n",
    "            return box_id\n",
    "        elif pos2 - pos1 == 1:\n",
    "            hor_links[pos1 - ((pos1 + 1) // (self.n + 1))] = True\n",
    "            box_id = []\n",
    "            check = self.is_box_completed(pos1, pos2, pos1 - (self.n + 1), pos2 - (self.n + 1), hor_links, ver_links)\n",
    "            if check:\n",
    "                box_id.append(pos1 - (self.n + 1))\n",
    "            check = self.is_box_completed(pos1, pos2, pos1 + (self.n + 1), pos2 + (self.n + 1), hor_links, ver_links)\n",
    "            if check:\n",
    "                box_id.append(pos1)\n",
    "            return box_id\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # removes a link from the given points by making the joining index False in the hor_links or ver_links\n",
    "    # does nothing if the link is absent\n",
    "    def remove_link(self, pos1, pos2, hor_links, ver_links):\n",
    "        e = Exception(\"Error\")\n",
    "        if pos1 > pos2:\n",
    "            pos1, pos2 = pos2, pos1\n",
    "        if (pos1 + 1) % (self.n + 1) == 0 and pos2 % (self.n + 1) == 0:\n",
    "            raise e\n",
    "        if (pos2 - pos1) == self.n + 1:\n",
    "            ver_links[pos1] = False\n",
    "        elif (pos2 - pos1) == 1:\n",
    "            hor_links[pos1 - ((pos1 + 1) // (self.n + 1))] = False\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # receives the corner(left topmost point of the box) value and changes its ownership to player name\n",
    "    def change_owner(self, corner, owners, player):\n",
    "        if corner != []:\n",
    "            owners[corner - ((corner + 1) // (self.n + 1))] = player\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # reverses the current player\n",
    "    def change_player(self):\n",
    "        if self.player == self.player1:\n",
    "            self.player = self.player2\n",
    "        else:\n",
    "            self.player = self.player1                 \n",
    "      \n",
    "                    \n",
    "    def total_rewardsPlayer1_calculator(self): #R\n",
    "        result = 0 \n",
    "        for obj in self.rewardsPlayer1:\n",
    "            result += obj.val\n",
    "        return result\n",
    "\n",
    "    def total_rewardsPlayer2_calculator(self):\n",
    "        result = 0 \n",
    "        for obj in self.rewardsPlayer2:\n",
    "            result += obj.val\n",
    "        return result\n",
    "    \n",
    "    # a random agent function \n",
    "    def randomAgent(self, printResult=True):\n",
    "        for _ in range(len(self.actions)):\n",
    "            if len(self.actions) > 0:\n",
    "                randomVar = random.choice(self.actions.copy())\n",
    "                self.play_game(randomVar[0], randomVar[1],printResult)\n",
    "    \n",
    "    def play_random(self, point1, point2, printResult=True):\n",
    "        game_player= self.player\n",
    "        self.play_game(point1,point2,printResult)\n",
    "        while (self.player!= game_player) & (self.gameOver==False):\n",
    "            randomVar= random.choice(self.actions.copy())\n",
    "            self.play_game(randomVar[0],randomVar[1],printResult)\n",
    "\n",
    "    def getTransitions(self):\n",
    "        self.transitions.clear()\n",
    "        for a in self.actions:\n",
    "            copy= self.state[:]\n",
    "            copy.append(a)\n",
    "            self.transitions.append((1/len(self.actions),copy))\n",
    "    \n",
    "    def get_states_from_transitions(self, transitions):\n",
    "        if isinstance(transitions, dict):\n",
    "            s1 = set(transitions.keys())\n",
    "            s2 = set(tr[1] for actions in transitions.values()\n",
    "                     for effects in actions.values()\n",
    "                     for tr in effects)\n",
    "            return s1.union(s2)\n",
    "        else:\n",
    "            print('Could not retrieve states from transitions')\n",
    "            return None\n",
    "    \n",
    "    def T(self, state):\n",
    "        copyA= self.actions[:]\n",
    "        for a in state:\n",
    "            copyA.remove(a)\n",
    "        transitions=[]\n",
    "        for a in copyA:\n",
    "            copy= copyA[:]\n",
    "            copy.append(a)\n",
    "            transitions.append((1/len(copyA),copy))\n",
    "        self.states= self.get_states_from_transitions(self.T(self.state))\n",
    "        return self.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utilily(game, action):\n",
    "    pos1 = game.dots.index(action[0])\n",
    "    pos2 = game.dots.index(action[1])\n",
    "    currentP= game.player\n",
    "    box_id = game.create_link(pos1, pos2, game.hor_links, game.ver_links)\n",
    "    amount_change=0 #amount of boxes that changed owner\n",
    "    for corner in box_id:\n",
    "        if game.change_owner(corner, game.owners, game.player):\n",
    "            amount_change+=1\n",
    "\n",
    "    game.actions.remove([action[0], action[1]])\n",
    "    game.state.append([action[0], action[1]])\n",
    "    if amount_change>0:\n",
    "        if game.player == game.player1:\n",
    "            reward = Reward(game.player1+ \"made a square\", amount_change)\n",
    "            game.rewardsPlayer1.append(reward)\n",
    "            reward = Reward(game.player1+ \"made a square\", -amount_change)\n",
    "            game.rewardsPlayer2.append(reward)\n",
    "        else:\n",
    "            reward = Reward(game.player2+\" made a square\", -amount_change)\n",
    "            game.rewardsPlayer1.append(reward)\n",
    "            reward = Reward(game.player2+\" made a square\", amount_change)\n",
    "            game.rewardsPlayer2.append(reward)\n",
    "    else:\n",
    "        game.change_player()  # changes the player\n",
    "    if currentP==game.player1:\n",
    "        return game.rewardsPlayer1[len(game.rewardsPlayer1)-1].val\n",
    "    return game.rewardsPlayer2[len(game.rewardsPlayer1)-1].val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Actions\n",
    "One action in this game will be making a connection between two dots. Each action from one player is followed by an action from the other player unless the first player has managed to create a box. The actions in this game consist of two coordinates where in between the connection should be formed. These include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions= [[\"a0\",\"a1\"],[\"a1\",\"a2\"],[\"b0\",\"b1\"],[\"b1\",\"b2\"],[\"c0\",\"c1\"],[\"c1\",\"c2\"],[\"a0\",\"b0\"],[\"b0\",\"c0\"],[\"a1\",\"b1\"],[\"b1\",\"c1\"],[\"a2\",\"b2\"],[\"b2\",\"c2\"]]\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These actions include all the possible horizontal and vertical actions. These actions can be activated by dots and boxes play game, where you input the two coordinates and returns the new state with your new action and the algorithms new action. All the actions by the algorithm for the computer play are the functions with comp in front of the name. These include:\n",
    "- comp_try_box \n",
    "- get_comp_turns\n",
    "- comp_play\n",
    "\n",
    "### 2.3. Transitions\n",
    "The transition of $(s'|s,a)$ where s' is the new state, s is the previous state and a represents one of the actions. $s'$ will be decided by the previous state in combination with the action, because it will depend on the new actions what the new stat looks like. The probability $P$ of these transitions will depend on the strategy of the algorithm.\n",
    "\n",
    "### 2.4. Rewards\n",
    "The reword of a specific transition, also  will The reword of a specific transition, also $R(s,a,s')$ will depend on how successful the algorithm was. If the algorithm is closer to creating a box, or did create a box, then the reword should be higher then actions that do the opposite. We will work with our own reward system that rewards a player when they form a box and when they win. When the opposite player get a box or a wins, you will get a negative reward.\n",
    "\n",
    "### 2.5. Policy\n",
    "The policy will be play steps that will result in the player ending the game with the most amount of boxes. This will result in a high reward. We will find out with Q-learning what this policy is going to look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game1= DotsAndBoxes(2)\n",
    "game1.show_game()\n",
    "for a in actions:\n",
    "    game1.play_game(a[0],a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Playing against a random opponent\n",
    "You can play against a random opponent by starting the game and playing with play_random. This function works the same as play_game only when it is the opponents turn it will automatically play a random action. To initialise the game to let the random player go first, you have to indicate in the initialisation that random play is true (this is set to false as default). Like the play_game in play_random and in the initialisation you can also indicate if you want to play the results or not (default is true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game3 = DotsAndBoxes(2,randomPlay=True, printResult=True)\n",
    "game3.play_random(\"a0\",\"a1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game3.play_random(\"b0\",\"b1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game3 = DotsAndBoxes(2)\n",
    "game3.play_random(\"a0\",\"a1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random agent playing against random agent\n",
    "This first example shows the random agent playing against another random agent. In 4.1 we will put this to the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DotsAndBoxes(2)\n",
    "game.randomAgent();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Random agent average score\n",
    "The average of both the random agents playing against each other comes close to zero. This is correct, because the average of one game would be that both random players get 2 boxes which results in two times -1 and two times +1 which results in an end result of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomGameAverage(aTimes):\n",
    "    totalPlayer1=0\n",
    "    totalPlayer2=0\n",
    "    for _ in range(aTimes):\n",
    "        game = DotsAndBoxes(2)\n",
    "        game.randomAgent(False)\n",
    "        totalPlayer1+= game.total_rewardsPlayer1_calculator()\n",
    "        totalPlayer2+= game.total_rewardsPlayer2_calculator()\n",
    "    averageP1= totalPlayer1/aTimes\n",
    "    averageP2= totalPlayer2/aTimes\n",
    "    return averageP1,averageP2\n",
    "\n",
    "getRandomGameAverage(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def value_iteration_instru(dab, iterations=20):\n",
    "#     U_over_time = []\n",
    "#     U1 = {s: 0 for s in dab.states}\n",
    "#     R, T, gamma = dab.total_rewardsPlayer1_calculator, dab.T, 0.9\n",
    "#     for _ in range(iterations):\n",
    "#         U = U1.copy()\n",
    "#         for s in dab.states:\n",
    "#             U1[s] = R(s) + gamma * max([sum([p * U[s1] for (p, s1) in T(s, a)])\n",
    "#                                         for a in dab.actions(s)])\n",
    "#         U_over_time.append(U)\n",
    "#     return U_over_time\n",
    "\n",
    "# game4 =DotsAndBoxes(2)\n",
    "# value_iteration_instru(game4.deepcopy(), iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, dab, Ne, Rplus, alpha=None):\n",
    "\n",
    "        self.gamma = 0.9\n",
    "        self.all_act = dab.actions\n",
    "        self.Ne = Ne  # iteration limit in exploration function\n",
    "        self.Rplus = Rplus  # large value to assign before iteration limit\n",
    "        self.Q = defaultdict(float)\n",
    "        self.Nsa = defaultdict(float)\n",
    "        self.s = None\n",
    "        self.a = None\n",
    "        self.r = None\n",
    "\n",
    "        if alpha:\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            self.alpha = lambda n: 1. / (1 + n)  # udacity video\n",
    "    \n",
    "    def updateActions(self, actions):\n",
    "        self.all_act=actions\n",
    "    \n",
    "    def f(self, u, n):\n",
    "        \"\"\"Exploration function. Returns fixed Rplus until\n",
    "        agent has visited state, action a Ne number of times.\n",
    "        Same as ADP agent in book.\"\"\"\n",
    "        if n < self.Ne:\n",
    "            return self.Rplus\n",
    "        else:\n",
    "            return u\n",
    "\n",
    "    def actions_in_state(self):\n",
    "        \"\"\"Return actions possible in given state.\n",
    "        Useful for max and argmax.\"\"\"\n",
    "        if len(self.all_act)==1:\n",
    "            return [None]\n",
    "        return self.all_act\n",
    "\n",
    "    def __call__(self, percept,term):\n",
    "        s1, r1 = self.update_state(percept)\n",
    "        Q, Nsa, s, a, r = self.Q, self.Nsa, self.s, self.a, self.r\n",
    "        alpha, gamma = self.alpha, self.gamma,\n",
    "        actions_in_state = self.actions_in_state\n",
    "\n",
    "        if term==1:\n",
    "            Q[s, None] = r1\n",
    "        if s is not None:\n",
    "            Nsa[s, a] += 1\n",
    "            Q[s, a] += alpha(Nsa[s, a]) * (r + gamma * max(Q[s1, a1]\n",
    "                                                           for a1 in actions_in_state(s1)) - Q[s, a])\n",
    "        if term==1:\n",
    "            self.s = self.a = self.r = None\n",
    "        else:\n",
    "            self.s, self.r = s1, r1\n",
    "            self.a = max(actions_in_state(), key=lambda a1: self.f(Q[s1, a1], Nsa[s1, a1]))\n",
    "        return self.a\n",
    "\n",
    "    def update_state(self, percept):\n",
    "        \"\"\"To be overridden in most cases. The default case\n",
    "        assumes the percept to be of type (state, reward).\"\"\"\n",
    "        return percept\n",
    "\n",
    "\n",
    "def run_single_trial(agent_program, dab):\n",
    "    \"\"\"Execute trial for given agent_program\n",
    "    and mdp. mdp should be an instance of subclass\n",
    "    of mdp.MDP \"\"\"\n",
    "\n",
    "    def take_single_action(dab, s, a):\n",
    "        \"\"\"\n",
    "        Select outcome of taking action a\n",
    "        in state s. Weighted Sampling.\n",
    "        \"\"\"\n",
    "        x = random.uniform(0, 1)\n",
    "        cumulative_probability = 0.0\n",
    "        for probability_state in dab.T():\n",
    "            probability, state = probability_state\n",
    "            cumulative_probability += probability\n",
    "            if x < cumulative_probability:\n",
    "                break\n",
    "        return state\n",
    "    \n",
    "    current_state = dab.state\n",
    "    while True:\n",
    "        current_reward = dab.total_rewardsPlayer1_calculator()\n",
    "        percept = (current_state, current_reward)\n",
    "        next_action = agent_program(percept,len(dab.actions))\n",
    "        if next_action is None:\n",
    "            break\n",
    "        current_state = take_single_action(dab.deepcopy(), current_state,next_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game4 =DotsAndBoxes(2)\n",
    "q_agent = QLearningAgent(game4, Ne=5, Rplus=2,alpha=lambda n: 60./(59+n) )\n",
    "for i in range(200):\n",
    "    run_single_trial(q_agent,game4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "game2 = DotsAndBoxes(2)\n",
    "game2.play_game(\"a1\", \"a2\",False)\n",
    "game2.play_game(\"b1\", \"b2\",False)\n",
    "game2.play_game(\"a1\", \"b1\", False)\n",
    "new_game = copy.deepcopy(game2)\n",
    "\n",
    "\n",
    "utilily(new_game, [\"a2\", \"b2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game2.show_game()\n",
    "# utilily(new_game, [\"a1\", \"b1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "2af4d1fb11621f50d08f1d6b423154fe8df1fd0bb312ebeaaac66930e83d3613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
